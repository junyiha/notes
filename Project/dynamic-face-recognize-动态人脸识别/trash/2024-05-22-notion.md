---
category: Project
date: 2024-05-22 09:00:00 +0800
layout: post
title: notion
tag: DynamicFaceRecognizeProject
---

+ 视频解码
+ 目标检测
+ 特征提取
+ 引擎处理
+ 特征值比较
  + 清单列表
    + 白名单
    + 黑名单
+ 生成结果

## 简述

+ 人脸识别技术目前已经广泛应用于安全，监控，一般身份识别，考勤，走失儿童搜救等领域，对于提升身份认证的效率起到了重要的作用。
+ 目前还有更深入的人脸识别的研究正在进行，包括性别识别，年龄估计，心情估计等，更高水平和更高准确率的人脸识别技术对于城市安全和非接触式身份认证有巨大的作用
  
+ 人脸识别问题宏观上分为两类：**人脸验证和人脸识别**
  + 人脸验证通常是做一对一的对比，判断两张图片中是否为同一人
  + 人脸识别通常是一对多的对比，判断照片中的人是否为数据库中的某一位

### 发展历史

+ 人脸识别受到多种因素影响，主要分为基础因素，内在因素和外在因素。
  + 基础因素是：人脸本身就相似，人的五官，轮廓大致相同
  + 内在因素是：人的内部属性，例如年龄变化，精神状态，化妆等
  + 外部因素是：成像质量的问题，比如相片的清晰程度，有无眼睛，口罩遮挡等
+ 对于人类来说，认出一个人是很容易的是清，对于计算机来说，图片**是由多维数字矩阵表示的，识别任务难度大**

+ 最早的人脸识别是半自动人脸识别，由人工标注人脸特征点，计算机根据特征点相对位置进行人脸匹配
+ 在1965-1990年间，人脸识别研究主要基于人脸几何结构特征和模板匹配的方法，利用几何特征提取人眼，口，鼻等重要特征点的位置，以及眼睛等重要器官的**几何直观形状作为分类特征**，并据此计算特征点之间相互位置和距离，用来衡量两幅人脸图像的相似程度
+ 1991-1997年，基于整体的方法较多，包括主成分分析（PCA）方法，线性鉴别分析（LDA）方法等。**这些方法通过寻找一组投影向量，将人脸降维，再将低维特征送入类似SVM等机器学习分类器中进行人脸分类**
+ 1998年至2013年间，很多借助深度相机，结构光，红外相机等设备辅助人脸识别的方法出现，使的人脸识别的精度大大提高，同时还有早期的基于特征的分类方法，**在人脸不同位置提取局部特征，得到的结果往往比整体方法更加具有鲁棒性**。类似的有从图像中提取HOG， LBP， SIFI， SURF特征，将各模块局部特征的向量串联，作为人脸的表示
  + 综合方法：先使用基于特征的方法获得局部特征，再使用子空间法（比如PCA，LDA）获得低维特征，将基于整体与基于局部特征的方法。这类方法中，GaussianFace在LFW上获得了最好的精度98.52%，几乎匹敌很多后来出现的深度学习方法

+ 2006年以后，深度学习开始得到研究人员重视，在国际期刊发表的数目越来越多。而后深度学习广泛应用于各种目标检测领域，2015年，Google团队的FaceNet在LFW数据集上的平均准确率达到了99.63%，基于深度学习

## 局部二值模式，LBP

+ 局部二值模式，`Local Binary Patterns, LBP`
  + 局部二值模式，是计算机视觉领域里用于**分类**的视觉算子。
  + LBP的核心思想就是：以中心像素的灰度值作为阈值，与其他的领域相比得到相应的二进制码来表示局部纹理特征。
+ LBP是提取局部特征作为判别依据的。LBP方法显著的优点是对光照不敏感，但是依然没有解决姿态和表情的问题

+ 在实际应用中，人脸验证（判断是否为同一人）， 人脸识别（这个人是谁）和人脸聚类（寻找类似的人）在自然场景应用仍然面临一些困难。
+ 为了降低背景和环境等因素带来的干扰，人脸识别一般先经过：人脸检测(`Face Detection`)， 人脸对齐(`Face Alignment`)等预处理，然后将人脸图像映射到欧几里得等空间，空间距离的长度代表了人脸图像的相似性。只要该影射空间生成，人脸识别验证和聚类等任务就显得不那么复杂。

### 欧几里得空间（线性代数 第九章）

+ 欧几里得空间(Euclidean space)，是指一类特殊的向量空间，对通常三维空间中的向量可以讨论长度，夹角等几何性质
+ 欧几里得空间就是在对现实空间的规则抽象和推广（从n <=3 推广到有限n维空间）。

## FaceNet -- Google

+ `FaceNet`，就是一个通用人脸识别系统：采用深度卷集网络（CNN）学习将图像影射到欧式空间。空间距离直接和图片相似度相关：同一个人的不同图像在空间距离很小，不同人的图像在空间中有较大的距离，可以用于人脸验证，识别和聚类。

+ 人脸识别的过程中有4个关键的步骤：
  + 人脸检测
    + 人脸检测的目的是寻找图片中人脸的位置。当发现有人脸出现在图片中，不管这个人脸是谁的，都会表基础人脸的坐标信息，或者将人脸切割出来。
    + 可以使用**方向梯度直方图(HOG)**来检测人脸位置。先将图片灰度化，接着计算图像中像素的梯度。通过将图像转变称HOG形式，就可以获得人脸的位置
  + 人脸对齐
    + 人脸对齐是将不同角度的人脸图像对齐成同一种标准的形状
    + 先定位人脸上的特征点，然后通过几何变换（仿射，旋转，缩放），使各个特征点对齐（将眼睛，嘴等部位移到相同的位置。
  + 人脸编码
    + 人脸图像的像素值会被转换成紧凑且可判别的特征向量，这也被称为模板(`tmplate`)。理想情况下，同一个主体的所有人脸都应该映射到相似的特征向量。
  + 人脸匹配
    + 在人脸匹配构建模块中，两个模块会进行比较，从而得到一个相似度分数，该分数给出了两者属于同一个主体的可能性。

+ `X * W = Y`
+ 人脸识别问题中`X`是图像，当然图像在计算机中的存储方式是数字矩阵对应图像的像素点阵，比如`1024 * 768`等，而每个像素点是用数值来表示RGB或者黑白灰，不同的图像所对应的数字矩阵是不同的，但是在数值分布上会呈现出一定的特征，比如人脸和五官，不管出现在图像中的哪个位置，对应的数值都会有一定的规律。
+ 对于人脸检测问题，`Y`是方框，把人脸能够装在方框中，准确的说也就是这个方框四个点的坐标值
+ 对于人脸特征点定位的问题，`Y`值就是这些特征点的坐标值。
+ 而对于年龄识别问题，这是标签值，身份识别也是标签值
+ **如此以来，人脸识别的相关问题就都转换称为基于数值矩阵的分类或者回归问题，标签值如果是男女老少这样的类别，那是分类问题，标签值如果是特征点或者定位框，那就是回归问题。

+ 对于图像问题最为常见的模型是**卷积神经网络(convolution neural networks)**
  + 简单理解卷积神经网络运用一系列的数学方法，建立多层结构来提取数据特征，基于这些数据特征进行判断预测。
  + 结构有些类似于人的神经网络视网膜采集像素，神经元提取颜色轮廓等信息，大脑再将图像信息与抽象概念进行比对，运用了数学的卷积方法，类似于神经网络，所以这个结构叫做卷积神经网络。
  + 在结构中中间的`hidden layers`，用于图像数字矩阵的特征提取，是可以复用的，对于分类问题，右边使用`classification`的结构。对于回归问题，用`regulation`的结构

# 图像特征提取

## 常见算法原理和性能

+ 计算机不认识图像，只认识数字。为了使计算机能够“理解”图像，从而具有真正意义上的“视觉”，将研究如何从图像中提取有用的数据或信息，得到图像的“非图像”的表示或描述，如数值，向量和符号等。这一过程就是**特征提取**，**而提取出来的这些“非图像”的表示或描述就是特征**。
+ 有了这些数值或向量形式的特征，就可以通过**训练过程**教会计算机如何懂得这些特征，从而使计算机具有识别图像的本领。

### 什么是图像特征？

+ 特征，是某一类对象区别于其他类对象的相应（本质）特点和特性，或是这些特点和特性的集合。特征是**通过测量或处理能够抽取的数据**。
+ 对于图像而言，每一幅图像都具有能够区别于其他类图像的自身特征，有些是可以直观地感受到的自然特征，例如亮度，边缘，纹理和色彩等；有些则是需要通过变换或者处理才能得到，例如矩形，直方图以及主成分等。

### 特征向量及其几何解释

+ **我们常常将某一类对象的多个或多种特性组合在一起，形成一个特征向量来代表该类对象，如果只有单个数值特征，则特征向量为一个一维向量；如果是n个特性的组合，则为一个n维特征向量。该类特征向量常常作为识别系统的输入。**
+ 实际上，一个n维特征就是位于**n维空间中的点**，而识别分类的任务就是找到对这个n维空间的一种划分。

### 特征提取的一般原则

+ 图像识别，实际上是一个分类的过程，为了识别出某图像所属的类别，我们需要将它与其他不同类别的图像区分开来。这就要求选取的特征不仅要能够很好地描述图像，更重要的是还要能够很好地区分不同类别的图像。
+ 我们希望选择那些在同类图像之间差异较小（较小的类内距），在不同类别的图像之间差异较大（较大的类间距）的图像特征，我们称之为最具有区分能力（most discriminative)的特征。
+ 此外，在特征提取中先验知识扮演着重要的角色，如果依靠先验知识来帮助我们选择特征也是需要持续关注的问题。

## 常见特征提取算法

### SIFT（尺度不变特征变换）

+ SIFT特征提取的实质，在不同的尺度空间上查找关键点（特征点），并计算出关键点的方向。SIFT所查找到的关键点是一些十分突出，不会因光照，仿射变换和噪音等因素而变化的点，如角点，边缘点，暗区的亮点及亮区的暗点等。

### HOG（方向梯度直方图）

+ HOG特征提取的实质，通过计算和统计图像局部区域的梯度方向直方图来构成特征。
+ HOG特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。

### ORB

+ ORB特征描述算法的运行时间远优于SIFT算法，可用于实时特征检测。
+ ORB特征基于FAST角点的特征点检测与描述技术，具有尺度与旋转不变性，同时对噪声及透视仿射也具有不变性，良好的性能使的ORB在进行特征描述时的应用场景十分广泛。

### HAAR

+ 人脸检测最为经典的算法：**`Haar-like`特征+`Adaboost`**。这是最为常用的物体检测的方法（最初用于人脸检测），也是用的最多的方法
+ 训练过程：输入图像->图像预处理->提取特征->训练分类器（而分类）->得到训练好的模型
+ 测试过程：输入图像->图像预处理->提取特征->导入模型->二分类(是不是所要检测的物体)

------------------------------------------------------------------

+ 小块的图像可以由基本的边缘构成，更结构化，更复杂的，就需要更高层次的特征表示，高层表达由底层表达组合而成。

+ 在计算机视觉里，网络的深度是实现网络好的效果的重要因素，输入特征的“登记”随着增加网络深度而变高。然而在网络深度不断加深的情况下，梯度消失和爆炸成为训练深层次的网络的障碍，导致网络无法收敛。
+ 虽然，归一初始化，各层输入归一化，使的可以收敛的网络的深度提升为原来的十倍，虽然网络收敛了，但是网络却开始退化了。

## 深度学习  --  提取特征

+ 特征提取(Feature extraction),在机器学习、模式识别和图像处理中有很多的应用,
+ 特征提取是从一个初始测量的资料集合中开始做，然后建构出富含资讯性而且不冗馀的导出值，称为**特征值（feature）**

+ 它可以帮助接续的学习过程和归纳的步骤，在某些情况下可以让人更容易对资料做出较好的诠释.
+ 特征提取是一个降低维度的步骤，初始的资料集合被降到更容易管理的族群（特征）以便于学习，同时保持描述原始资料集的精准性与完整性。

+ 相较于原始庞大的资料集合需要很大量的资源来描述，特征提取可以减少需要描述这些资料的资源。当我们分析复杂资料时，其中一个主要的问题是源自于变数的数量过多
+ 分析很多个变数一般来说需要很大量的内存以及计算能力，同时太多变数也可能造成分类问题的算法有过度拟合于训练资料的现象，因此对新的采样无法有效地归纳。
+ **特征提取是处理变数组合并维持资料充足的准确性时，常通称的术语。很多机器学习的实作者认为适当的特征提取是有效模型构建的关键**。