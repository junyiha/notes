## 视频基础知识和视频格式

+ 网站上的视频，是常说的**网络流媒体**
+ 将视频缓存到本地成一个文件，是常说的**本地视频文件**

### 视频封装格式（简称视频格式，也称为容器）

+ 视频格式是视频播放软件为了能够播放视频文件而赋予视频文件的一种识别符号
+ 换句话讲，视频格式规定了和播放器的通信协议

+ 首先，`MP4, AVI, MKV`等都是本地视频文件的后缀，在wiindows系统下，用于提示操作系统应该采用哪个应用程序打开。
+ 而在流媒体领域，这些都被称为**视频封装格式**，因为除了音视频流外，它们还包含了一些辅助信息以及组织音频的方式。
+ 不同格式的视频在不同平台上用户体验不同，很大原因在于对音视频的组织方式带来的差异。

+ 视频封装格式，是在编码的音视频基础上进行一次“包装”，添加与播放相关的协议数据。（不一定正确）

### 视频协议

+ 视频协议，**是针对网络流媒体而言的**，也就是只有在有网络时通过浏览器或者移动端APP才能看到的视频，目前常见的协议有RTSP， RTMP， HLS，HTTP等

+ 有的文章会把视频协议归入视频封装格式，因为它们都同时携带了音视频和metadata，以及协议/格式需要的其他信息。
+ 以FFMpeg为例，它并不区分视频格式和视频协议。

### 视频流

+ 常见的词语有：
  + h264码流，yuv流，编码流，解码流，原始流，裸流，或者 未压缩的流

+ 归纳的讲，视频流，一定只有两种形式
  + 经过压缩算法压缩的流数据，称为**编码流**，又因为目前压缩/编码算法以H264为主，因此常常称为**H264码流**
  + 未经过压缩的流数据，是解码后的流数据，称为**原始流**，可以想象视频是由一幅一幅在时间上连续的“图像”组成的，而因为视频内部的“图像”是YUV，因此也常常称为**YUV流**

+ 总结
  + h264码流，压缩后的流， 编码流 ： 是压缩/编码后的视频流
  + yuv流，解码流，未压缩的流     ： 是未经过压缩/编码的视频流
  + 裸流，是一个具有歧义的词，是上下文内容，既可以是前者，也可以是后者

 + 因此，在阅读任何流媒体相关的文章时，看到视频流都应该搞清楚，是编码/压缩的,还是没有
   + 在生活中，接触到的视频文件绝大部分都是编码/压缩后的
   + 在网络传输场景中，绝大部分也是编码/压缩后的。
   + **只有在视频播放时，看到的是一帧帧被转码为RGB的解码后的视频流**

+ 编码/压缩在流媒体领域是一项非常重要的技术：
  + 从**H264码流**到**YUV流**的过程称为解码，反之称为编码

### 帧

+ 流媒体领域，**流**很重要，流的基本元素**帧**同样重要。

+ 对于视频编码/压缩而言，它的核心是采用尽量小的空间存储一组时间上连续的帧数据
+ 而对于视频解码而言，就是把被编码/压缩后的一组数据尽量恢复成原来的样子。
  + 能够被100%恢复的编码/压缩算法称为无损压缩，反之称为有损压缩

+ 帧，可以联想成平时看到的一幅幅“图像”，只不过我们平时接触的图片是**RGB格式**的，而视频帧通常是**YUV格式**的

+ 帧，为什么采用YUV格式？YUV是什么？
  + 在达到最大压缩率的情况下，能够保证对人眼感知的失真度最小。YUV的三个通道中，其中Y表示明亮度，也就是灰阶值；而U和V表示的则是色度。科学家研究发现，人眼对UV的敏感度最低，因此可以大比例地压缩UV两个通道的数值
  + 为了向前兼容黑白电视

+ YV12， YU12， NV12， NV21等，统称为**视频的存储格式**，也就是说，计算机是如何存储一帧视频的

+ 视频编解码而衍生的帧名词
  + I帧， P帧， B帧和IDR帧
  + GOP， Group Of Pictures，一般来说，指的是两个I帧之间的间隔
  + PTS, Presentation Time Stamp， 显示时间戳，它用来告诉播放器该什么时候显示这一帧的数据
  + DTS, Decoding Time Stamp， 解码时间戳，它的意义在于告诉解码器在什么时候解码这一帧的数据

-----------------------------------------------------------------------------------------------------------------------------------------

## JPG-JPEG（JFIF） 文件解码-文件结构

+ 参考链接：`https://blog.csdn.net/ymlbright/`

+ `JPEG`文件使用的数据存储方式有多种。最常用的格式称为`JPEG`文件交换格式（`JPEG File Interchange Format，JFIF`）
+ 而JPEG文件大体上由一个个数据段组成，数据段包含：标记码(Tag)、数据长度、数据

+ 标记码由两个字节构成，其前一个字节是固定值`0xFF`，后一个字节则根据不同意义有不同数值
+ 在每个标记码之前还可以添加数目不限的无意义的0xFF填充，也就说连续的多个0xFF可以被理解为一个0xFF，并表示一个标记码的开始。而在一个完整的两字节的标记码后，就是该标记码对应的压缩数据流，记录了关于文件的诸种信息。
+ 常用的标记有`SOI、APP0、DQT、SOF0、DHT、DRI、SOS、EOI`
+ 注意，SOI等都是标记的名称。在文件中，标记是以标记码形式出现的。例如SOI的标记代码为0xFFD8，即在JPEG文件中的如果出现数据0xFFD8，则表示此处为一个SOI标记
  + SOI  （0xFFD8） -- 代表JFIF图像数据的开始
  + APP0 （0xFFE0） -- 应用程序标记 0 
  + APPn （0xFFEn） -- 拓展应用程序标记 2~15， 为其他应用程序保留 
  + DQT  （0xFFDB） -- 量化表，存储了对扫描数据进行量化的 8*8 矩阵
  + SOFx （0xFFCx） -- 图像帧开始
  + DHT  （0xFFC4） -- Huffman表，存储了对扫描数据进行压缩的Huffman表，共4张，DC直流2张，AC交流2张
  + SOS  （0xFFDA） -- 扫描数据开始 
  + scanData       -- 图像的压缩数据，为了不与之前的标记码（Tag）混淆，数据中遇到 0xFF 时，需要进行判断
    + 0xFF00：表示 0xFF 是图像数据的组成部分
    + 0xFFD0~0xFFD7：RSTn标记，遇到标记时，对差分解码变量进行重置（归0）
    + 0xFFD9：图像结束标记，图像压缩数据至此结束
  + EOI  （0xFFD9） -- 代表JFIF图像数据的结束，即文件结尾

-----------------------------------------------------------------------------------------------------------------------------------------

## 腾讯 开发者社区 

+ 文章链接：`https://cloud.tencent.com/developer/article/1385273`

+ 就音频而言，无论是算法多样性，Codec种类还是音频编解码复杂程度都远远比视频要高。

+ 视频的Codec目前还主要是**以宏块为处理单元**，预测加变换的混合编码框架，例如H.264和H.265都是在这一框架下

### 直播和点播

+ 从广义上来讲，直播和点播都是一种视频播放场景
+ 如果想要简单地区分二者，确实可以通过判断当前播放的视频画面是不是实时的来区分
  + 如果是实时的画面就是直播，
  + 如果不是实时的画面就是点播

+ 直播
  + 视频直播播放的视频内容是实时的视频画面，视频源是实时的媒体流。
  + 视频直播的播放内容稍纵即逝，无法回退和快进。
  + 日常生活中的视频直播场景非常多，比如直播带货、视频会议、赛事直播等

+ 点播
  + 视频点播播放的视频内容是非实时的视频画面，
  + 视频源是已经存在的视频文件或者媒体源，可以多次使用，可以回退和快进。
  + 日常生活中的视频点播场景也非常多，比如有线电视、网络点播、短视频等

+ 直播和点播的工作流程
  + 视频直播会**涉及一个比较完整的视频处理流程**，包括视频画面和声音采集、视频编码、组包发送、网络传输、收包解包、视频解码、视频渲染和声音播放等
  + 视频点播包括的流程就比较少了，一般只涉及文件读取、网络传输、视频解码、视频渲染和声音播放等流程，不会涉及视频画面和声音采集、视频编码、组包

+ 技术架构
  + 视频直播，**常见的低延时方案大多是 RTC （Real time communication）方案**，比如 WebRTC；大会直播类的场景一般是 CDN 方案，常用 rtmp、hls 等流媒体协议方案
  + 视频点播，常用的有电视信号和网络协议，比如 http，https 等，视频格式有 m3u8、mp4、flv、mkv、mxf 等。由于上述网络协议和传输信号的差异，视频直播和视频点播的播放器方案有所不同，也是二者的显著差异之一

-----------------------------------------------------------------------------------------------------------------------------------------

## RTC

### 什么是RTC？

+ RTC（Real time communication）实时通信，是实时音视频的一个简称，我们常说的RTC技术一般指的是WebRTC技术，已经被 W3C 和 IETF 发布为正式标准

+ 由于几乎所有主流浏览器都支持 WebRTC 标准 API ，因此也让浏览器之间无插件化的音视频互通成为可能， 大大降低了音视频开发的门槛，开发者只需要调用 WebRTC API 即可快速构建出音视频应用

+ 更广义的RTC技术，不单单局限于音视频，包括IM(Instant messaging,即时通讯)、图片、白板、文件共享等富媒体在内的实时交互也属于RTC技术范畴。 

### 一套完善的RTC服务应用的技术

+ RTMP只是TCP上的一个标准协议，所以接入是一个标准体系，推流端可以是OBS( Open Broadcaster Software)这种直播软件工具，也可自开发rtmp推流工具，播放端可以是Flash播放器（Adobe 2020 12月份已经弃用）、服务端有技术成熟的CDN(Content Delivery Network，即内容分发网络)技术和设施进行分发、Native的播放器或者flv.js/hls.js这种开源播放器组件，遵循rtmp、flv、hls标准即可，接入成本比较低。而一个完善的RTC服务应用，需要从推流端、服务端、到拉流端，一整套完整的全链路闭环技术。

+ 互动连麦+服务端转推rtmp至CDN，CDN分发给观众。